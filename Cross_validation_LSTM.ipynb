{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEFHxtzg+LfTSYbMiMkInV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G-Conard/ds595-final-project/blob/main/Cross_validation_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZjhMHAU_yKr",
        "outputId": "3c969e56-490c-4cf0-da08-f3ba5dc25fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 22 Complete [00h 04m 26s]\n",
            "val_mse: 0.0056853159330785275\n",
            "\n",
            "Best val_mse So Far: 0.0024269085843116045\n",
            "Total elapsed time: 01h 18m 51s\n",
            "42/42 [==============================] - 6s 93ms/step - loss: 0.0012 - mse: 0.0012\n",
            "Test MSE: 0.0011869187001138926\n",
            "Results summary\n",
            "Results in my_dir/weather_prediction\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_mse\", direction=\"min\")\n",
            "\n",
            "Trial 0016 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: tanh\n",
            "dropout: 0.1\n",
            "optimizer: adam\n",
            "tuner/epochs: 20\n",
            "tuner/initial_epoch: 7\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0015\n",
            "Score: 0.0024269085843116045\n",
            "\n",
            "Trial 0017 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: tanh\n",
            "dropout: 0.1\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 20\n",
            "tuner/initial_epoch: 7\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0013\n",
            "Score: 0.0025877903681248426\n",
            "\n",
            "Trial 0015 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: tanh\n",
            "dropout: 0.1\n",
            "optimizer: adam\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 3\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0009\n",
            "Score: 0.0035956748761236668\n",
            "\n",
            "Trial 0019 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: tanh\n",
            "dropout: 0.2\n",
            "optimizer: adam\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.003665962489321828\n",
            "\n",
            "Trial 0013 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: tanh\n",
            "dropout: 0.1\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 3\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0000\n",
            "Score: 0.0037841754965484142\n",
            "\n",
            "Trial 0018 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: tanh\n",
            "dropout: 0.2\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.004026262555271387\n",
            "\n",
            "Trial 0020 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: relu\n",
            "dropout: 0.1\n",
            "optimizer: adam\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.004287607967853546\n",
            "\n",
            "Trial 0014 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "activation: relu\n",
            "dropout: 0.2\n",
            "optimizer: adam\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 3\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0011\n",
            "Score: 0.004893801640719175\n",
            "\n",
            "Trial 0012 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "activation: tanh\n",
            "dropout: 0.2\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 3\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0006\n",
            "Score: 0.004931926727294922\n",
            "\n",
            "Trial 0021 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "activation: relu\n",
            "dropout: 0.2\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.0056853159330785275\n"
          ]
        }
      ],
      "source": [
        "# Install Keras Tuner\n",
        "!pip install keras-tuner\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras_tuner import Hyperband, Objective\n",
        "\n",
        "# Load and prepare data\n",
        "data = pd.read_csv('/content/weather_stations_data.csv')\n",
        "data = data.dropna()\n",
        "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "data.set_index('timestamp', inplace=True)\n",
        "data = data[['heat_index']].values.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "sc = scaler.fit_transform(data)\n",
        "\n",
        "timestep = 288\n",
        "X, Y = [], []\n",
        "for i in range(len(sc) - timestep):\n",
        "    X.append(sc[i:(i + timestep)])\n",
        "    Y.append(sc[i + timestep])\n",
        "X, Y = np.array(X), np.array(Y)\n",
        "X = X[:, :, None]\n",
        "\n",
        "split_idx = int(0.8 * len(X))\n",
        "X_train, Y_train = X[:split_idx], Y[:split_idx]\n",
        "X_test, Y_test = X[split_idx:], Y[split_idx:]\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Choice('units', values=[32, 64]),\n",
        "                   activation=hp.Choice('activation', values=['relu', 'tanh']),\n",
        "                   input_shape=(timestep, 1),\n",
        "                   return_sequences=True))\n",
        "    model.add(Dropout(rate=hp.Choice('dropout', values=[0.1, 0.2])))\n",
        "    model.add(LSTM(units=hp.Choice('units', values=[32, 64]),\n",
        "                   activation=hp.Choice('activation', values=['relu', 'tanh']),\n",
        "                   return_sequences=False))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=hp.Choice('optimizer', ['adam', 'rmsprop']),  # Fixed to one type for simplicity\n",
        "                  loss='mse',\n",
        "                  metrics=['mse'])\n",
        "    return model\n",
        "\n",
        "# Set up the tuner\n",
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective=Objective(\"val_mse\", direction=\"min\"),\n",
        "    max_epochs=20,  # Adjusted inside the search\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='weather_prediction')\n",
        "\n",
        "# Perform the search with limited epoch choices\n",
        "for epochs in [10, 20]:  # Limited to two epoch values\n",
        "    for batch_size in [32, 64]:  # Limited to two batch sizes\n",
        "        tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "loss, mse = best_model.evaluate(X_test, Y_test)\n",
        "print(\"Test MSE:\", mse)\n",
        "\n",
        "# Print a summary of all trials\n",
        "tuner.results_summary()\n"
      ]
    }
  ]
}