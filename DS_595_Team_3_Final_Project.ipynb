{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G-Conard/ds595-final-project/blob/main/DS_595_Team_3_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpANA5RrB5qJ"
      },
      "source": [
        "Website https://siglosrrd.org/estacion-de-medicion-ambiental-mariato/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYDvaepxBVWj",
        "outputId": "210bb84c-46b5-46ab-993f-7eadbee27d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA *not* available\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as py\n",
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "import concurrent.futures\n",
        "from tabulate import tabulate\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import linear_model\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import SparsePCA\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.decomposition import MiniBatchSparsePCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from numpy import savetxt\n",
        "from numpy import loadtxt\n",
        "import datetime\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torch.manual_seed(50) # this makes results reproducable\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#this is a check to see if a GPU machine that pytorch can use for training\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA available')\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('CUDA *not* available')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f673c3-fc72-41b3-a4a4-4b3330c2f465",
        "id": "1aqF-anaOn6h"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id  station_id  tempc  humidity  dewptc  windchillc  winddir  \\\n",
            "0  22954.0         3.0  35.11      56.0   25.00       35.11    295.0   \n",
            "1  22956.0         3.0  35.50      57.0   25.72       35.50    217.0   \n",
            "2  22958.0         3.0  35.50      56.0   25.39       35.50    236.0   \n",
            "3  22960.0         3.0  34.61      56.0   24.61       34.61    276.0   \n",
            "4  22962.0         3.0  33.78      57.0   24.11       33.78    242.0   \n",
            "\n",
            "   windspeedkmh  windgustkmh  rainmm  ...   UV  indoortempc  indoorhumidity  \\\n",
            "0          5.76         9.37     0.0  ...  0.0        36.39            51.0   \n",
            "1          3.60         7.19     0.0  ...  0.0        36.28            53.0   \n",
            "2          5.76         9.37     0.0  ...  0.0        36.22            54.0   \n",
            "3          2.88         7.19     0.0  ...  0.0        36.11            51.0   \n",
            "4          1.80         7.19     0.0  ...  0.0        35.78            52.0   \n",
            "\n",
            "   absbarohpa  barohpa  rad_tempc  rad_hum  aqpm25  heat_index       timestamp  \n",
            "0     1010.30  1010.30      37.89     44.0     6.0       45.07  3/8/2024 16:08  \n",
            "1     1010.19  1010.19      37.89     47.0     8.0       46.62  3/8/2024 16:13  \n",
            "2     1010.19  1010.19      37.89     47.0     8.0       46.62  3/8/2024 16:19  \n",
            "3     1010.19  1010.19      37.22     45.0     5.0       43.89  3/8/2024 16:24  \n",
            "4     1010.30  1010.30      35.61     50.0     5.0       42.16  3/8/2024 16:29  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "source": [
        "#temporary use of prior data set from case study 1 to test code until real dataset imported\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv('/content/weather_stations_data.csv')\n",
        "\n",
        "raw_data = data #use this raw_data var to act as the raw dataset once imported please\n",
        "\n",
        "print(raw_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksb0rd0rM7hY"
      },
      "outputs": [],
      "source": [
        "#Analize the individual predictors and their correlations with the target variable\n",
        "\n",
        "#the Feature to predict in the dataset, and the Column predictors in the datasets\n",
        "Feature = [\"heat_index\"]\n",
        "Labels = ['tempc', 'humidity', 'dewptc', 'windchillc', 'winddir', 'windspeedkmh', 'windgustkmh', 'rainmm', 'dailyrainmm', 'weeklyrainmm', 'monthlyrainmm', 'yearlyrainmm', 'solarradiation', 'UV', 'indoortempc', 'indoorhumidity', 'absbarohpa', 'barohpa', 'rad_tempc', 'rad_hum', 'aqpm25']\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "cor = raw_data.corr()\n",
        "sns.heatmap(cor, annot=True,cmap=plt.cm.Reds)\n",
        "plt.show()\n",
        "\n",
        "sns.pairplot(raw_data)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "Temp_x=raw_data[Labels]\n",
        "Temp_y=raw_data[Feature]\n",
        "selectKbest = SelectKBest(score_func=f_regression, k='all')\n",
        "Temp_fit = selectKbest.fit(Temp_x,Temp_y)\n",
        "plt.bar(x=Temp_x.columns,height=Temp_fit.scores_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS24wv5D2pDq"
      },
      "outputs": [],
      "source": [
        "#methods testing function\n",
        "\n",
        "def RegressionModelsTester(dataset, feature, method, CVFolds=4):\n",
        "\n",
        "  Labels = dataset[2]\n",
        "\n",
        "  CAList = [(\"None\", None, 0)] \\\n",
        "         + [(\"PCA\", PCA(n_components=pc), pc) for pc in range(1, len(Labels)+1)] \\\n",
        "         + [(\"SparsePCA\", SparsePCA(n_components=pc, random_state=0), pc) for pc in range(1, len(Labels)+1)] \\\n",
        "         + [(\"MiniBatchSparsePCA\", MiniBatchSparsePCA(n_components=pc, random_state=0), pc) for pc in range(1, len(Labels)+1)] \\\n",
        "         + [(\"FactorAnalysis\", FactorAnalysis(n_components=pc, random_state=0), pc) for pc in range(1, len(Labels)+1)] \\\n",
        "         + [(\"IncrementalPCA\", IncrementalPCA(n_components=pc, batch_size=200), pc) for pc in range(1, len(Labels)+1)] \\\n",
        "         + [(\"FastICA\", FastICA(n_components=pc, random_state=0), pc) for pc in range(1, len(Labels)+1)] \\\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for ca in CAList:\n",
        "\n",
        "    for split in range(1, 10):\n",
        "\n",
        "      X = dataset[0][Labels]\n",
        "      y = dataset[0][feature]\n",
        "\n",
        "      if not ca[1] is None:\n",
        "        #component analysis\n",
        "        sc = StandardScaler()\n",
        "        CA = ca[1]\n",
        "        X = sc.fit_transform(X)\n",
        "        X = CA.fit_transform(X)\n",
        "\n",
        "      # split training data and testing\n",
        "      Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=(split/10),shuffle=True, random_state=1)\n",
        "\n",
        "      model = method[0]\n",
        "      model.fit(Xtrain,ytrain)\n",
        "      ypred = model.predict(Xtest)\n",
        "\n",
        "      MAE=mean_absolute_error(ypred,ytest)\n",
        "      MSE=mean_squared_error(ypred,ytest)\n",
        "      RMSE=np.sqrt(mean_squared_error(ypred,ytest))\n",
        "      R2=r2_score(ypred,ytest)\n",
        "\n",
        "      MAPE = mean_absolute_percentage_error(ytest, ypred)\n",
        "\n",
        "      #cross vaidation\n",
        "      crossValLists = cross_val_score(model, X, y, cv=CVFolds)\n",
        "      avg_cross_val_score = (sum(crossValLists) / len(crossValLists))\n",
        "\n",
        "      result.append([dataset[1], method[1], (split/10), ca[0], ca[2], CVFolds, avg_cross_val_score, R2, MSE, RMSE, MAE, MAPE])\n",
        "\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK9KdoATFkfJ"
      },
      "outputs": [],
      "source": [
        "#perform feature engineering here to create multiple trial data sets then add the data set and label into FeatureEngineeredDatasetsList below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZm4pxMy3ALS"
      },
      "outputs": [],
      "source": [
        "#This block is to take all the datasets to run through the Regressor Function above to evaluate all possible aspects for all models with each dataset and record and output the results\n",
        "\n",
        "FeatureEngineeredDatasetsList = [(raw_data, \"Raw Dataset\", Labels)] #(dataset, string label, dataset column labels)\n",
        "\n",
        "\n",
        "\n",
        "methodlist = [(linear_model.LinearRegression(), \"Linear\"),\n",
        "              (KNeighborsRegressor(n_neighbors=20), \"KNeighborsRegressor\"),\n",
        "              (linear_model.Ridge(), \"Ridge\"),\n",
        "              (linear_model.Lasso(), \"Lasso\"),\n",
        "              (linear_model.BayesianRidge(), \"BayesianRidge\"),\n",
        "              (DecisionTreeRegressor(), \"DecisionTreeRegressor\"),\n",
        "              (RandomForestRegressor(), \"RandomForestRegressor\")]\n",
        "\n",
        "\n",
        "cv_folds = 4 #for cross vallidation\n",
        "\n",
        "Final_Regression_Analysis_Results = []\n",
        "\n",
        "# Create a thread pool to test all the datasets using all models\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=len(FeatureEngineeredDatasetsList)*len(methodlist)) as pool:\n",
        "    # Submit individual function calls with their arguments to the thread pool\n",
        "    evaluators = [pool.submit(RegressionModelsTester, dataset, Feature, method, cv_folds) for dataset in FeatureEngineeredDatasetsList for method in methodlist]\n",
        "\n",
        "    # Wait for all tasks to complete\n",
        "    for evaluator in concurrent.futures.as_completed(evaluators):\n",
        "        # Retrieve the result of each task (this will block until the task completes)\n",
        "        Final_Regression_Analysis_Results.extend(evaluator.result())\n",
        "\n",
        "#Print the Final Analysis Results Fully\n",
        "print(tabulate(Final_Regression_Analysis_Results, headers=[\"Dataset\", \"Model\", \"Train/Test Split\", \"CA Method\", \"Primary Components\", \"CV Folds\", \"Avg. Cross Val Score\", \"R^2\", \"MSE\", \"RMSE\", \"MAE\", \"MAPE\"],tablefmt=\"grid\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo8tx5bUmZgR"
      },
      "outputs": [],
      "source": [
        "\n",
        "#analize the results for the best performance\n",
        "best_avg_cv_score = 0\n",
        "best_avg_cv_score_idx = 0\n",
        "\n",
        "best_R2 = 0\n",
        "best_R2_idx = 0\n",
        "\n",
        "best_MSE = 0\n",
        "best_MSE_idx = 0\n",
        "\n",
        "best_RMSE = 0\n",
        "best_RMSE_idx = 0\n",
        "\n",
        "best_MAE = 0\n",
        "best_MAE_idx = 0\n",
        "\n",
        "best_MAPE = 0\n",
        "best_MAPE_idx = 0\n",
        "\n",
        "avg_cv_score = 6\n",
        "r2 = 7\n",
        "mse = 8\n",
        "rmse = 9\n",
        "mae = 10\n",
        "mape = 11\n",
        "\n",
        "\n",
        "for idx in range(len(Final_Regression_Analysis_Results)):\n",
        "\n",
        "  result = Final_Regression_Analysis_Results[idx]\n",
        "\n",
        "  #CV Score\n",
        "  if result[avg_cv_score] > best_avg_cv_score:\n",
        "    best_avg_cv_score = result[avg_cv_score]\n",
        "    best_avg_cv_score_idx = idx\n",
        "\n",
        "  #R^2\n",
        "  if result[r2] > best_R2:\n",
        "    best_R2 = result[r2]\n",
        "    best_R2_idx = idx\n",
        "\n",
        "  #MSE\n",
        "  if result[mse] > best_MSE:\n",
        "    best_MSE = result[mse]\n",
        "    best_MSE_idx = idx\n",
        "\n",
        "  #RMSE\n",
        "  if result[rmse] > best_RMSE:\n",
        "    best_RMSE = result[rmse]\n",
        "    best_RMSE_idx = idx\n",
        "\n",
        "  #MAE\n",
        "  if result[mae] > best_MAE:\n",
        "    best_MAE = result[mae]\n",
        "    best_MAE_idx = idx\n",
        "\n",
        "  #MAPE\n",
        "  if result[mape] > best_MAPE and result[mape] >= 0:\n",
        "    best_MAPE = result[mape]\n",
        "    best_MAPE_idx = idx\n",
        "\n",
        "\n",
        "Best_Regression_Results = [[\"Best Avg. Cross Val Score\"] + Final_Regression_Analysis_Results[best_avg_cv_score_idx],\n",
        "                           [\"Best R^2\"] + Final_Regression_Analysis_Results[best_R2_idx],\n",
        "                           [\"Best MSE\"] + Final_Regression_Analysis_Results[best_MSE_idx],\n",
        "                           [\"Best RMSE\"] + Final_Regression_Analysis_Results[best_RMSE_idx],\n",
        "                           [\"Best MAE\"] + Final_Regression_Analysis_Results[best_MAE_idx],\n",
        "                           [\"Best MAPE\"] + Final_Regression_Analysis_Results[best_MAPE_idx]]\n",
        "\n",
        "print(tabulate(Best_Regression_Results, headers=[\"Best Metric\", \"Dataset\", \"Model\", \"Train/Test Split\", \"CA Method\", \"Primary Components\", \"CV Folds\", \"Avg. Cross Val Score\", \"R^2\", \"MSE\", \"RMSE\", \"MAE\", \"MAPE\"],tablefmt=\"grid\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnDo8tzZPikP"
      },
      "outputs": [],
      "source": [
        "def train(training_inputs, training_outputs, network, epochs, learning_rate, batch_size, loss_function, print_interval):\n",
        "\n",
        "  network.train()\n",
        "\n",
        "  train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(training_inputs).float(),\n",
        "                                                 torch.from_numpy(training_outputs).float())\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "\n",
        "  optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  track_losses = np.zeros(epochs)\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "\n",
        "      for batch_idx, (X, y) in enumerate(train_loader):\n",
        "\n",
        "          data = X\n",
        "\n",
        "          data = data.to(DEVICE)\n",
        "\n",
        "          output = network.forward(data)\n",
        "\n",
        "          loss = loss_function(output, y.view([-1, 1]).to(DEVICE))\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "      training_loss = loss.item()**.5\n",
        "      track_losses[epoch-1] = training_loss\n",
        "      if epoch % print_interval == 0:\n",
        "          print('epoch: %4d training loss:%10.3e time:%7.1f'%(epoch, training_loss, time.time()-start))\n",
        "\n",
        "  return network, track_losses\n",
        "\n",
        "\n",
        "def model_eva(XTrain,XTest,yTrain,yTest,model):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  XTrain_th = torch.from_numpy(XTrain).float().to(DEVICE)\n",
        "  XTest_th = torch.from_numpy(XTest).float().to(DEVICE)\n",
        "  #yTrain_th=torch.Tensor(yTrain).cuda()\n",
        "  #yTest_th=torch.Tensor(yTest).cuda()\n",
        "\n",
        "  yTrain_pred = model.forward(XTrain_th)\n",
        "\n",
        "  yTrain_pred_np = yTrain_pred.cpu().detach().numpy().reshape(-1)\n",
        "\n",
        "  yTest_pred = model.forward(XTest_th)\n",
        "  yTest_pred_np = yTest_pred.cpu().detach().numpy().reshape(-1)\n",
        "\n",
        "  MAE_train=mean_absolute_error(yTrain_pred_np,yTrain)\n",
        "  MSE_train=mean_squared_error(yTrain_pred_np,yTrain)\n",
        "  RMSE_train=np.sqrt(mean_squared_error(yTrain_pred_np,yTrain))\n",
        "  R2_train=r2_score(yTrain_pred_np,yTrain)\n",
        "\n",
        "  MAE_test=mean_absolute_error(yTest_pred_np,yTest)\n",
        "  MSE_test=mean_squared_error(yTest_pred_np,yTest)\n",
        "  RMSE_test=np.sqrt(mean_squared_error(yTest_pred_np,yTest))\n",
        "  R2_test=r2_score(yTest_pred_np,yTest)\n",
        "\n",
        "  return MAE_train,MSE_train,RMSE_train,R2_train,MAE_test,MSE_test,RMSE_test,R2_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "halI03hzQQhR"
      },
      "outputs": [],
      "source": [
        "#NN Models go gere to try then add the model instantiation to the NN_Methods_List below\n",
        "\n",
        "#test network 1\n",
        "class testnetworks(nn.Module):\n",
        "    def __init__(self, modelnum):\n",
        "        super().__init__()\n",
        "        self.modelnum = modelnum\n",
        "        self.structureslist = [nn.Sequential(\n",
        "                                    nn.Linear(7,5),\n",
        "                                    nn.Sigmoid(),\n",
        "                                    nn.Linear(5,4),\n",
        "                                    nn.LeakyReLU(),\n",
        "                                    nn.Linear(4,3),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(3,1)\n",
        "                                    ),\n",
        "                                nn.Sequential(\n",
        "                                    nn.Linear(7,5),\n",
        "                                    nn.Sigmoid(),\n",
        "                                    nn.Linear(5,4),\n",
        "                                    nn.Sigmoid(),\n",
        "                                    nn.Linear(4,3),\n",
        "                                    nn.Sigmoid(),\n",
        "                                    nn.Linear(3,1)\n",
        "                                    )\n",
        "                               ]\n",
        "\n",
        "        self.structure = self.structurelist[self.modelnum]\n",
        "\n",
        "    def getNumModels(self):\n",
        "      return len(self.structureslist)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.structure(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHjtXlyLQRYv"
      },
      "outputs": [],
      "source": [
        "def NN_Results_Tester(dataset, feature, nnmethod, tests, criterion, print_interval):\n",
        "\n",
        "  X = dataset[0][dataset[2]].values\n",
        "  y = dataset[0][feature].values\n",
        "\n",
        "  for test in tests:\n",
        "\n",
        "    batch_size_test = test[0]\n",
        "    num_epochs_test = test[1]\n",
        "    learning_rate_test = test[2]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for split in range(1, 10):\n",
        "\n",
        "      Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=(split/10),shuffle=True, random_state=1)\n",
        "\n",
        "      NNmodel = nnmethod[0].to(DEVICE)\n",
        "\n",
        "      network, losses = train(Xtrain, ytrain, NNmodel, num_epochs_test, learning_rate_test, batch_size_test, criterion, print_interval)\n",
        "\n",
        "      MAE_train,MSE_train,RMSE_train,R2_train,MAE_test,MSE_test,RMSE_test,R2_test = model_eva(Xtrain,Xtest,ytrain,ytest,network)\n",
        "      results.append([dataset[1], nnmethod[1], (split/10), num_epochs_test, learning_rate_test, batch_size_test, MAE_train,MSE_train,RMSE_train,R2_train,MAE_test,MSE_test,RMSE_test,R2_test])\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXRlXsw_Ruu4"
      },
      "outputs": [],
      "source": [
        "NN_Methods_List = [(testnetworks(i), \"NN Model \" + str(i)) for i in range(testnetworks(0).getNumModels())]\n",
        "\n",
        "tests = [(50, 500, 1e-2), #batch_size, num_epochs, learning_rate\n",
        "         (100, 1000, 1e-3),\n",
        "         (200, 2000, 1e-4)]\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print_interval = 500\n",
        "\n",
        "\n",
        "Final_NN_Analysis_Results = []\n",
        "\n",
        "# Create a thread pool to test all the datasets using all models\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=len(FeatureEngineeredDatasetsList)*len(NN_Methods_List)) as pool:\n",
        "    # Submit individual function calls with their arguments to the thread pool\n",
        "    evaluators = [pool.submit(NN_Results_Tester, dataset, Feature, nn_method, tests, criterion, print_interval) for dataset in FeatureEngineeredDatasetsList for nn_method in NN_Methods_List]\n",
        "\n",
        "    # Wait for all tasks to complete\n",
        "    for evaluator in concurrent.futures.as_completed(evaluators):\n",
        "        # Retrieve the result of each task (this will block until the task completes)\n",
        "        Final_NN_Analysis_Results.extend(evaluator.result())\n",
        "\n",
        "#Print the Final Analysis Results Fully\n",
        "print(tabulate(Final_NN_Analysis_Results, headers=[\"Dataset\", \"Model\", \"Train/Test Split\", \"Num Epochs\", \"Learning Rate\", \"Batch Size\", \"Training MAE\", \"Training MSE\", \"Training RMSE\", \"Training R^2\", \"Test MAE\", \"Test MSE\", \"Test RMSE\", \"Test R^2\"],tablefmt=\"grid\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ey7IYFhJmfuV"
      },
      "outputs": [],
      "source": [
        "\n",
        "#analize the results for the best performance\n",
        "best_Training_MAE = 0\n",
        "best_Training_MAE_idx = 0\n",
        "\n",
        "best_Training_MSE = 0\n",
        "best_Training_MSE_idx = 0\n",
        "\n",
        "best_Training_RMSE = 0\n",
        "best_Training_RMSE_idx = 0\n",
        "\n",
        "best_Training_R2 = 0\n",
        "best_Training_R2_idx = 0\n",
        "\n",
        "best_Test_MAE = 0\n",
        "best_Test_MAE_idx = 0\n",
        "\n",
        "best_Test_MSE = 0\n",
        "best_Test_MSE_idx = 0\n",
        "\n",
        "best_Test_RMSE = 0\n",
        "best_Test_RMSE_idx = 0\n",
        "\n",
        "best_Test_R2 = 0\n",
        "best_Test_R2_idx = 0\n",
        "\n",
        "train_mae = 3\n",
        "train_mse = 4\n",
        "train_rmse = 5\n",
        "train_r2 = 6\n",
        "test_mae = 7\n",
        "test_mse = 8\n",
        "test_rmse = 9\n",
        "test_r2 = 10\n",
        "\n",
        "for idx in range(len(Final_NN_Analysis_Results)):\n",
        "\n",
        "  result = Final_NN_Analysis_Results[idx]\n",
        "\n",
        "  #Training MAE\n",
        "  if result[train_mae] > best_Training_MAE:\n",
        "    best_Training_MAE = result[train_mae]\n",
        "    best_Training_MAE_idx = idx\n",
        "\n",
        "  #Training MSE\n",
        "  if result[train_mse] > best_Training_MSE:\n",
        "    best_Training_MSE = result[train_mse]\n",
        "    best_Training_MSE_idx = idx\n",
        "\n",
        "  #Training RMSE\n",
        "  if result[train_rmse] > best_Training_RMSE:\n",
        "    best_Training_RMSE = result[train_rmse]\n",
        "    best_Training_RMSE_idx = idx\n",
        "\n",
        "  #Training R2\n",
        "  if result[train_r2] > best_Training_R2:\n",
        "    best_Training_R2 = result[train_r2]\n",
        "    best_Training_R2_idx = idx\n",
        "\n",
        "  #Testing MAE\n",
        "  if result[test_mae] > best_Test_MAE:\n",
        "    best_Test_MAE = result[test_mae]\n",
        "    best_Test_MAE_idx = idx\n",
        "\n",
        "  #Testing MSE\n",
        "  if result[test_mse] > best_Test_MSE:\n",
        "    best_Test_MSE = result[test_mse]\n",
        "    best_Test_MSE_idx = idx\n",
        "\n",
        "  #Testing RMSE\n",
        "  if result[test_rmse] > best_Test_RMSE:\n",
        "    best_Test_RMSE = result[test_rmse]\n",
        "    best_Test_RMSE_idx = idx\n",
        "\n",
        "  #Testing R2\n",
        "  if result[test_r2] > best_Test_R2:\n",
        "    best_Test_R2 = result[test_r2]\n",
        "    best_Test_R2_idx = idx\n",
        "\n",
        "\n",
        "Best_NN_Results = [[\"Best Training MAE\"] + Final_NN_Analysis_Results[best_Training_MAE_idx],\n",
        "                   [\"Best Training MSE\"] + Final_NN_Analysis_Results[best_Training_MSE_idx],\n",
        "                   [\"Best Training RMSE\"] + Final_NN_Analysis_Results[best_Training_RMSE_idx],\n",
        "                   [\"Best Training R2\"] + Final_NN_Analysis_Results[best_Training_R2_idx],\n",
        "                   [\"Best Testing MAE\"] + Final_NN_Analysis_Results[best_Test_MAE_idx],\n",
        "                   [\"Best Testing MSE\"] + Final_NN_Analysis_Results[best_Test_MSE_idx],\n",
        "                   [\"Best Testing RMSE\"] + Final_NN_Analysis_Results[best_Test_RMSE_idx],\n",
        "                   [\"Best Testing R2\"] + Final_NN_Analysis_Results[best_Test_R2_idx]]\n",
        "\n",
        "print(tabulate(Best_NN_Results, headers=[\"Best Metric\", \"Dataset\", \"Model\", \"Train/Test Split\", \"Num Epochs\", \"Learning Rate\", \"Batch Size\", \"Training MAE\", \"Training MSE\", \"Training RMSE\", \"Training R^2\", \"Test MAE\", \"Test MSE\", \"Test RMSE\", \"Test R^2\"],tablefmt=\"grid\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrPifqheYxRU"
      },
      "outputs": [],
      "source": [
        "#comparison of the best Regression models and the best NN Models\n",
        "print(tabulate(Best_Regression_Results, headers=[\"Best Metric\", \"Dataset\", \"Model\", \"Train/Test Split\", \"CA Method\", \"Primary Components\", \"CV Folds\", \"Avg. Cross Val Score\", \"R^2\", \"MSE\", \"RMSE\", \"MAE\", \"MAPE\"],tablefmt=\"grid\"))\n",
        "print(tabulate(Best_NN_Results, headers=[\"Best Metric\", \"Dataset\", \"Model\", \"Train/Test Split\", \"Num Epochs\", \"Learning Rate\", \"Batch Size\", \"Training MAE\", \"Training MSE\", \"Training RMSE\", \"Training R^2\", \"Test MAE\", \"Test MSE\", \"Test RMSE\", \"Test R^2\"],tablefmt=\"grid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKhurto-XueS"
      },
      "outputs": [],
      "source": [
        "#import a fresh new daily set of data to then use as a heirarical means to cross validate the models we like best here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}